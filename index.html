<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Tru-POMDP: Task Planning Under Uncertainty via Tree of Hypotheses and Open-Ended POMDPs</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Tru-POMDP: Task Planning Under Uncertainty via Tree of Hypotheses and Open-Ended POMDPs</h1>
            <div class="is-size-5 publication-authors">
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure>
        <img src="static/images/model.png" alt="图像的简要描述" >
        <figcaption>The architecture for Tru-POMDP. (a) Task Input: Human instruction and the observed scene graph. (b) Tree of Hypothesis: An LLM infers target objects, target areas, and initial locations, producing weighted particles. (c) Hybrid Belief Update: Bayesian filtering updates the belief using particle prediction and elimination, and augments the filtered belief with LLM particles. (d) Online POMDP Planning: Belief tree search computes the optimal action with the help of dynamic action branching and an LLM-written rollout policy.</figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Task planning under uncertainty is essential for home-service robots operating in the real world. 
            Tasks involve ambiguous human instructions, hidden or unknown object locations, and open-vocabulary object types, leading to significant open-ended uncertainty and a boundlessly large planning space. 
            To address these challenges, we propose Tru-POMDP, a planner that combines structured belief generation using Large Language Models (LLMs) with principled POMDP planning. 
            Tru-POMDP introduces a hierarchical <i>Tree of Hypotheses</i> (TOH), which systematically queries an LLM to construct high-quality particle beliefs over possible world states and human goals. 
            We further formulate an open-ended POMDP model that enables rigorous Bayesian belief tracking and efficient belief-space planning over these LLM-generated hypotheses. 
            Experiments on complex object rearrangement tasks across diverse kitchen environments show that \algname significantly outperforms state-of-the-art LLM-based and LLM-tree-search hybrid planners, 
            achieving higher success rates with significantly better plans, stronger robustness to ambiguity and occlusion, and greater planning efficiency.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

  <!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/BJTiYobI-qU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


  <!-- Paper Introduction -->
<section class="section hero is-small">  

<div class="hero-body">
  <div class="container ">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
             we propose Tru-POMDP, a new algorithm for task planning under uncertainty that tightly integrates commonsense reasoning by LLMs with explicit belief tracking and principled POMDP planning. Our main contributions include: 
          </p>

          <ul>
            <li> The first framework to integrate LLM-based reasoning with principled POMDP planning for household tasks. </li>
            <li> A novel hybrid belief modeling approach that integrates LLM-generated hypotheses with principled Bayesian filtering. </li>
            <li> A POMDP model for open-ended object rearrangement tasks and a practical belief-tree search planner for solving such tasks efficiently under large-scale uncertainty. </li>
          </ul>

        </div>
      </div>
    </div>
    </div>
  </div>
</section>



<!-- Image carousel -->
<section class="section hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
      <h2 class="title is-3">Experiment</h2>


      <figure>
        <img src="static/images/planned results.png" alt="图像的简要描述" >
        <figcaption>Planned results.</figcaption>
      </figure>

        <p>
            We compare Tru-POMDP against a set of strong baselines, including both pure LLM-based planners and tree search planners integrated with LLM reasoning. 
        </p>

        <ul>
            <li> ReAct: : A closed-loop LLM-based planner that selects actions based on current observations and immediate feedback from the environment.  </li>
            <li> Reflexion: An extension of <i>ReAct</i> that adds a reflection module. Upon repeated failures, it analyzes the history and generates a revised plan. For fair comparison under online planning, we disable environment resets and trigger reflection after three consecutive failed actions. </li>
            <li> ReAct* and Reflexion*: Prompt-augmented variants that provide the LLM with additional structured descriptions of the task domain, including object types, action semantics, and goal structures. </li>
            <li> LLM-MCTS: A tree search method that generates a maximum-likelihood hypothesis of the task goal and hidden object placements using an LLM. It then performs Monte Carlo Tree Search (MCTS), repeatedly querying the LLM to guide action selection during simulation. </li>
        </ul>
          
      
        <figure>
        <img src="static/images/exp1.png" alt="图像的简要描述" >
        <figcaption>Performance comparison of TRU-POMDP and baselines. Each bar represents the average value with standard error (SE). In (c), the dashed line indicates the maximum allowed step number.</figcaption>
        </figure>
  
      
        <p>
            We conduct experiment xxxxx.
        </p>

      

      <figure>
        <img src="static/images/abl1.png" alt="图像的简要描述" >
        <figcaption>Results for Ablation Study. Each bar shows average values with standard error (SE).</figcaption>
      </figure>
        </div/>
          </div/>
        </div/
  </div>
</div>
</section>
<!-- End image carousel -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
